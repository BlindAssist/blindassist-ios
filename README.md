# BlindAssist

<p>
  <a href="https://travis-ci.org/gi097/blindassist-ios">
    <img src="https://img.shields.io/travis/gi097/blindassist-ios/develop.svg?style=flat-square" alt="build" />
  </a>
  <a href="http://starveller.sigsev.io/gi097/blindassist-ios">
    <img src="http://starveller.sigsev.io/api/repos/gi097/blindassist-ios/badge" alt="stars" />
  </a>
  <a href='https://coveralls.io/github/gi097/blindassist-ios?branch=develop'>
    <img src='https://img.shields.io/coveralls/gi097/blindassist-ios.svg?style=flat-square' alt='Coverage Status' />
  </a>
</p>

BlindAssist is an iOS application which has the goal to support blind people
on the road. Since I have a blind brother, I decided to create this open source
project.

The assisting process will be done using deep learning, image segmentation
and translating the inference results to sentences which will be spoken out loud 
by tts (text to speech).

Currently BlindAssist uses CoreML. You can clone my other repo to get that model
to use it with this app.

https://github.com/gi097/blindassist-scripts

# Help is needed!
Do you have great ideas, or do you want to support my work? Get in touch or contribute!

# Example
Click on the image below to see a YouTube movie of the results.
[![video thumbnail](https://img.youtube.com/vi/eb-ESNV_PEI/0.jpg)](https://youtu.be/eb-ESNV_PEI)
