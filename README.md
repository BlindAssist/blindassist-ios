# BlindAssist

[![Build Status](https://travis-ci.org/gi097/blindassist-ios.svg?branch=develop)](https://travis-ci.org/gi097/blindassist-ios)
[![Stars](http://starveller.sigsev.io/api/repos/gi097/blindassist-ios/badge)](http://starveller.sigsev.io/gi097/blindassist-ios)
[![Coverage Status](https://coveralls.io/repos/github/gi097/blindassist-ios/badge.svg?branch=develop)](https://coveralls.io/github/gi097/blindassist-ios?branch=develop)
[![License](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](LICENSE)

More information about this project can be found here:
https://heartbeat.fritz.ai/community-spotlight-blindassist-792b4211af42

BlindAssist is an iOS application which has the goal to support blind people
on the road. Since I have a blind brother, I decided to create this open source
project.

The assisting process will be done using deep learning, image segmentation
and translating the inference results to sentences which will be spoken out loud 
by tts (text to speech).

Currently BlindAssist uses CoreML. You can run the `download_model.sh` script to
get the prebuilt model.

The source of the model can be found here:

https://github.com/BlindAssist/blindassist-scripts

# Help is needed!
Do you have great ideas, or do you want to support my work? Get in touch or contribute!

# Example
Click on the image below to see a YouTube movie of the results.
[![video thumbnail](https://img.youtube.com/vi/eb-ESNV_PEI/0.jpg)](https://youtu.be/eb-ESNV_PEI)
